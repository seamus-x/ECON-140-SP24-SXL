{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECON 140 - Problem Set 5\n",
    "\n",
    "## INSTRUCTIONS\n",
    "\n",
    "* Please step through this problem set, produce or fix the code, and run it to see its output. Consider the non-coding questions and write down a brief answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run the code below to install and load the necessary packages for this problem set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "packlist <- c(\"wooldridge\", \"ivreg\", \"modelsummary\")\n",
    "install.packages(packlist[!(packlist %in% installed.packages()[, 1])])\n",
    "\n",
    "library(ivreg)\n",
    "library(modelsummary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement Error and Attenuation Bias\n",
    "\n",
    "We are going to create a Monte Carlo simulation to study the effect of measurement errors on an OLS estimator, namely attenuation bias, and the use of 2SLS to correct for this bias. Let's begin with the code for a single iteration of data generation and estimation. As usual, we will begin by defining a set of parameters. Copy and paste the code below into the code block and run it.\n",
    "\n",
    "```R\n",
    "# Step 1\n",
    "n_iters <- 1000\n",
    "sample_size <- 200\n",
    "\n",
    "b0 <- 10\n",
    "b1 <- 5\n",
    "b2 <- 3\n",
    "\n",
    "c0 <- 5\n",
    "c1 <- 1\n",
    "c2 <- 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a data generating process that simulates measurement error in one covariate in a bivariate regression. We are able to observe outcome variable $y$, which is generated according to\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 v + \\beta_2 x_2 + \\varepsilon\n",
    "$$\n",
    "The $\\beta$'s are encoded as `b`s in the code. We can observe $x_2$, which is an exogenous covariate that we will generate as a random number according to $x_2 \\sim N(5, 100)$, but not $v$. Instead, we observe $x_1$, which is approximation of $v$ with measurement error such that\n",
    "$$\n",
    "x_1=v+\\delta\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\delta \\sim N(0, 9)\n",
    "$$\n",
    "\n",
    "and $v$ is in turn generated from two additional exogenous variables $w$ and $z$ according to\n",
    "\n",
    "$$\n",
    "v = \\gamma_0 + \\gamma_1 w + \\gamma_2 z + \\xi\n",
    "$$\n",
    "\n",
    "where the $\\gamma$'s are coded as `c`s in the code and we generate each variabe according to\n",
    "\n",
    "$$\n",
    "w \\sim N(5, 9)\\newline\n",
    "z \\sim N(3, 25)\\newline\n",
    "\\xi \\sim N(0, 36)\n",
    "$$\n",
    "\n",
    "We start by generating all the exogenous variables by completing the code below. Hint: The two parameters in the $N(a, b)$ are mean and variance, while the function `rnorm()` requires mean and standard error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2\n",
    "x2 <- rnorm(___)\n",
    "w <- rnorm(___)\n",
    "z <- rnorm(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then generate $v$ and $x_1$ consecutively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3\n",
    "v <- c0 + c1 * w + c2 * z + rnorm(___)\n",
    "x1 <- v + rnorm(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's generate $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4\n",
    "y <- b0 + b1 * v + b2 * x2 + rnorm(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will regress $y$ against $x_1$ and $x_2$ first using OLS, then 2SLS with either $w$ or $z$ (or both) as an instrument for $x_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Step 5\n",
    "lm1 <- lm(___)\n",
    "ivm1 <- ivreg(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `modelsummary()` to compare the two results from above side by side (use argument `output = jupyter` to display a readable table in Datahub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "modelsummary(___, output = \"jupyter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the coefficient on $x_1$ differ in the two models? Why is that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now run a Monte Carlo simulation of the data generating process and the estimations above for the previously defined number of times and collect the results. The output of the simulation should be the distributions of the OLS and the 2SLS coefficient estimates on $x_1$ in their respective histogram side by side. Complete the code below. Inside the loop you need to repeat steps 2 through 5, then save the coefficient estimates from each iteration to the results vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "results_ols <- rep(___)\n",
    "results_2sls <- rep(___)\n",
    "\n",
    "for(___){\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "hist(results_ols)\n",
    "hist(results_2sls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on the mean and standard deviation of each set of results. Which one indicates bias? What kind of bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's repeat the previous Monte Carlo simulation, except we will change the value of `b1` from 5 to -5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "b1 <- -5\n",
    "\n",
    "results_ols <- rep(___)\n",
    "results_2sls <- rep(___)\n",
    "\n",
    "for(___){\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "hist(results_ols)\n",
    "hist(results_2sls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the bias go the direction you had anticipated? How does the bias here differ from OVB in terms of the direction or sign of the bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Standard Error\n",
    "\n",
    "We will once again use the `saving` dataset from package `wooldridge` for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data(saving, package = \"wooldridge\")\n",
    "head(saving)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use `lm()` to regress `inc` and `sav`, respectively, against `size`, `educ`, `age`, and `black` and save the results as `lm_inc` and `lm_sav`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "lm_inc <- lm(___, data = saving)\n",
    "lm_sav <- lm(___, data = saving)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `modelsummary()` to display the above two regression results side by side. Label the columns \"Income\" and \"Savings\" as applicable. Use robust standard errors type \"HC1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "modelsummary(___, output = \"jupyter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use `modelsummary()` to display the results from `lm_ic` in three different columns, each with `vcov` type, respectively, \"iid\", \"stata\", and \"robust\". Label each column accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "modelsummary(___, output = \"jupyter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the result from above, for which variables does the standard error go up from \"iid\" to \"stata\" or \"robust\"? And for which ones does it go down?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot `inc` against `educ` and `size` in their respective scatter plots side by side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "par(mfrow = c(1, 2))\n",
    "plot(inc ~ educ, data = saving)\n",
    "plot(inc ~ size, data = saving)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the two scatter plot above, and the differences between OLS and robust standard errors from previous questions, remark on how the standard error estimate is upwardly or downwardly biased in OLS depending on the direction of heteroskedasticy (*i.e* fanning out toward higher values or lower values on a particular covariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
